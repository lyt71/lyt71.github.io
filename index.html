<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/css/1e83ba7336cc88b6.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-fd9cee151a2f9132.js"/><script src="/_next/static/chunks/fd9d1056-bb11881ef41582aa.js" async=""></script><script src="/_next/static/chunks/23-d4169bb1b2b13904.js" async=""></script><script src="/_next/static/chunks/main-app-6ac864bfa9c2a4db.js" async=""></script><script src="/_next/static/chunks/548-510bb30c9b0bc6ca.js" async=""></script><script src="/_next/static/chunks/742-7023ff07d49000d3.js" async=""></script><script src="/_next/static/chunks/737-b831f966e0626836.js" async=""></script><script src="/_next/static/chunks/app/page-7128724577c3be1a.js" async=""></script><script src="/_next/static/chunks/0e5ce63c-e21fe8bbb1ba0e0f.js" async=""></script><script src="/_next/static/chunks/860-f66ad5e413f0575e.js" async=""></script><script src="/_next/static/chunks/app/layout-e5a652e031f6cc17.js" async=""></script><title>Yiting Liu</title><meta name="description" content="Ph.D. Candidate, Control Science and Engineering, Xidian University, Xi&#x27;an, China"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"/><meta property="og:title" content="Yiting Liu"/><meta property="og:description" content="Ph.D. Candidate, Control Science and Engineering, Xidian University, Xi&#x27;an, China"/><meta property="og:url" content="https://lyt71.github.io"/><meta property="og:site_name" content="Yiting Liu"/><meta property="og:locale" content="en_US"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Yiting Liu"/><meta name="twitter:description" content="Ph.D. Candidate, Control Science and Engineering, Xidian University, Xi&#x27;an, China"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="16x16"/><script src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="min-h-screen bg-background font-sans antialiased max-w-2xl mx-auto py-12 sm:py-24 px-6 __variable_d65c78"><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&false)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}else{c.add('light')}if(e==='light'||e==='dark'||!e)d.style.colorScheme=e||'light'}catch(e){}}()</script><main class="flex flex-col min-h-[100dvh] space-y-10"><section id="hero"><div class="mx-auto w-full max-w-2xl space-y-8"><div class="gap-2 flex justify-between"><div class="flex-col flex flex-1 space-y-1.5"><div class="flex"><span class="inline-block text-2xl font-bold tracking-tighter sm:text-4xl xl:text-5xl/none" style="opacity:0;filter:blur(8px);transform:translateY(8px)">Hi, I&#x27;m Yiting Liu ðŸ‘‹</span></div><div class="flex"><span class="inline-block max-w-[600px] md:text-xl" style="opacity:0;filter:blur(8px);transform:translateY(8px)">Ph.D. Candidate, Control Science and Engineering, Xidian University, Xi&#x27;an, China</span></div></div><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><span class="relative flex shrink-0 overflow-hidden rounded-full size-28 border"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">YT</span></span></div></div></div></section><section id="about"><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><h2 class="text-xl font-bold">About</h2></div><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><div class="prose max-w-full text-pretty font-sans text-sm text-muted-foreground dark:prose-invert"><p>Welcome to my academic homepage. I am a Ph.D. candidate at Xidian University, focusing on sparse optimization, machine learning, and evolutionary computation. Please explore the different sections to learn more about my research and academic journey.</p></div></div></section><section id="education"><div class="flex min-h-0 flex-col gap-y-3"><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><h2 class="text-xl font-bold">Education</h2></div><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><a class="block cursor-pointer" href="https://www.xidian.edu.cn"><div class="rounded-lg bg-card text-card-foreground flex"><div class="flex-none"><span class="relative flex shrink-0 overflow-hidden rounded-full border size-12 m-auto bg-muted-background dark:bg-foreground"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">X</span></span></div><div class="flex-grow ml-4 items-center flex-col group"><div class="flex flex-col"><div class="flex items-center justify-between gap-x-2 text-base"><h3 class="inline-flex items-center justify-center font-semibold leading-none text-xs sm:text-sm">Xidian University<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right size-4 translate-x-0 transform opacity-0 transition-all duration-300 ease-out group-hover:translate-x-1 group-hover:opacity-100 rotate-0"><path d="m9 18 6-6-6-6"></path></svg></h3><div class="text-xs sm:text-sm tabular-nums text-muted-foreground text-right">2022 - 2025</div></div><div class="font-sans text-xs">Ph.D. in Control Science and Engineering</div><div class="font-sans text-xs">GPA: 95.14/100 (Top 1%)</div><div class="font-sans text-xs">Awards: Outstanding Doctoral Candidate (2023â€“2024), Outstanding Student (2022â€“2024), Shenglu Scholarship (2024), Ceyear Scholarship (2025)</div></div></div></div></a></div><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><a class="block cursor-pointer" href="https://www.xidian.edu.cn"><div class="rounded-lg bg-card text-card-foreground flex"><div class="flex-none"><span class="relative flex shrink-0 overflow-hidden rounded-full border size-12 m-auto bg-muted-background dark:bg-foreground"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">X</span></span></div><div class="flex-grow ml-4 items-center flex-col group"><div class="flex flex-col"><div class="flex items-center justify-between gap-x-2 text-base"><h3 class="inline-flex items-center justify-center font-semibold leading-none text-xs sm:text-sm">Xidian University<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right size-4 translate-x-0 transform opacity-0 transition-all duration-300 ease-out group-hover:translate-x-1 group-hover:opacity-100 rotate-0"><path d="m9 18 6-6-6-6"></path></svg></h3><div class="text-xs sm:text-sm tabular-nums text-muted-foreground text-right">2020 - 2022</div></div><div class="font-sans text-xs">M.S. in Electronic Science and Technology</div><div class="font-sans text-xs">GPA: 90.64/100 (Top 5%)</div><div class="font-sans text-xs">Awards: Special Freshman (2020), Outstanding Student (2021), Peng Cheng Lab OpenI Community Excellent Developer (2022)</div></div></div></div></a></div><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><a class="block cursor-pointer" href="https://www.hnu.edu.cn"><div class="rounded-lg bg-card text-card-foreground flex"><div class="flex-none"><span class="relative flex shrink-0 overflow-hidden rounded-full border size-12 m-auto bg-muted-background dark:bg-foreground"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">H</span></span></div><div class="flex-grow ml-4 items-center flex-col group"><div class="flex flex-col"><div class="flex items-center justify-between gap-x-2 text-base"><h3 class="inline-flex items-center justify-center font-semibold leading-none text-xs sm:text-sm">Hunan University<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right size-4 translate-x-0 transform opacity-0 transition-all duration-300 ease-out group-hover:translate-x-1 group-hover:opacity-100 rotate-0"><path d="m9 18 6-6-6-6"></path></svg></h3><div class="text-xs sm:text-sm tabular-nums text-muted-foreground text-right">2016 - 2020</div></div><div class="font-sans text-xs">B.S. in Electronic Information Engineering</div><div class="font-sans text-xs">GPA: 85.38/100 (Top 10%)</div><div class="font-sans text-xs">Awards: Outstanding Student (2017â€“2019)</div></div></div></div></a></div></div></section><section id="skills"><div class="flex min-h-0 flex-col gap-y-3"><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><h2 class="text-xl font-bold">Skills</h2></div><div class="flex flex-wrap gap-1"><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><div class="inline-flex items-center rounded-md border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80">Python</div></div><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><div class="inline-flex items-center rounded-md border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80">Matlab</div></div><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><div class="inline-flex items-center rounded-md border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80">OpenCV</div></div><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><div class="inline-flex items-center rounded-md border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80">PyTorch</div></div><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><div class="inline-flex items-center rounded-md border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80">TensorFlow</div></div><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><div class="inline-flex items-center rounded-md border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80">NumPy</div></div><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><div class="inline-flex items-center rounded-md border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80">React</div></div><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><div class="inline-flex items-center rounded-md border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80">Next.js</div></div><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><div class="inline-flex items-center rounded-md border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80">Typescript</div></div><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><div class="inline-flex items-center rounded-md border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80">Node.js</div></div></div></div></section><section id="Publications"><div class="space-y-12 w-full py-12"><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><div class="flex flex-col items-center justify-center space-y-4 text-center"><div class="space-y-2"><div class="inline-block rounded-lg bg-foreground text-background px-3 py-1 text-sm">Publications</div><h2 class="text-3xl font-bold tracking-tighter sm:text-5xl">Check out my work</h2><p class="text-muted-foreground md:text-xl/relaxed lg:text-base/relaxed xl:text-xl/relaxed">My research focuses on sparse optimization, machine learning, and evolutionary computation. I explore collaborative, data-driven methods in machine learning, using sparse modeling and optimization to improve robustness, efficiency, and interpretability.</p></div></div></div><div class="grid grid-cols-1 gap-3 sm:grid-cols-2 max-w-[800px] mx-auto"><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><div class="rounded-lg bg-card text-card-foreground flex flex-col overflow-hidden border hover:shadow-lg transition-all duration-300 ease-out h-full"><a class="block cursor-pointer" href="https://ieeexplore.ieee.org/abstract/document/10613908"><img alt="Collaborative Self-Supervised Evolution for Few-Shot Remote Sensing Scene Classification" loading="lazy" width="500" height="300" decoding="async" data-nimg="1" class="h-40 w-full overflow-hidden object-cover object-top" style="color:transparent" src="/tgrs_paper.png"/></a><div class="flex flex-col px-2"><div class="space-y-1"><h3 class="font-semibold tracking-tight mt-1 text-base">Collaborative Self-Supervised Evolution for Few-Shot Remote Sensing Scene Classification</h3><time class="font-sans text-xs">Y. Liu, J. Li, M. Gong, et al.</time><div class="hidden font-sans text-xs underline print:visible"></div><div class="prose max-w-full text-pretty font-sans text-xs text-muted-foreground dark:prose-invert"><p>An evolutionary strategy is used to search for optimal auxiliary task combinations to improve few-shot remote sensing scene classification. <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=36">IEEE Transactions on Geoscience and Remote Sensing</a>, 2024.</p></div></div></div><div class="text-pretty font-sans text-sm text-muted-foreground mt-auto flex flex-col px-2"><div class="mt-2 flex flex-wrap gap-1"><div class="inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]">Collaborative Evolution Strategy</div><div class="inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]">Few-shot Learning</div><div class="inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]">Remote Sensing Scene Classification</div><div class="inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]">Self-supervised Learning</div></div></div><div class="flex items-center pt-2 px-2 pb-2"><div class="flex flex-row flex-wrap items-start gap-1"><a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/10613908"><div class="items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80 flex gap-2 px-2 py-1 text-[10px]"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-globe size-3"><circle cx="12" cy="12" r="10"></circle><path d="M12 2a14.5 14.5 0 0 0 0 20 14.5 14.5 0 0 0 0-20"></path><path d="M2 12h20"></path></svg>Website</div></a></div></div></div></div><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><div class="rounded-lg bg-card text-card-foreground flex flex-col overflow-hidden border hover:shadow-lg transition-all duration-300 ease-out h-full"><a class="block cursor-pointer" href="https://ieeexplore.ieee.org/abstract/document/10092910"><img alt="Nonzero Degree-Based Multiobjective Cooperative Coevolutionary for Block Sparse Recovery" loading="lazy" width="500" height="300" decoding="async" data-nimg="1" class="h-40 w-full overflow-hidden object-cover object-top" style="color:transparent" src="/tevc_paper.png"/></a><div class="flex flex-col px-2"><div class="space-y-1"><h3 class="font-semibold tracking-tight mt-1 text-base">Nonzero Degree-Based Multiobjective Cooperative Coevolutionary for Block Sparse Recovery</h3><time class="font-sans text-xs">Y. Liu, H. Li, M. Gong, A. K. Qin</time><div class="hidden font-sans text-xs underline print:visible"></div><div class="prose max-w-full text-pretty font-sans text-xs text-muted-foreground dark:prose-invert"><p>A multiobjective cooperative coevolutionary method integrates the spatial structure of block sparse signals to reduce search difficulty and improve efficiency. <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=4235">IEEE Transactions on Evolutionary Computation</a>, 2024.</p></div></div></div><div class="text-pretty font-sans text-sm text-muted-foreground mt-auto flex flex-col px-2"><div class="mt-2 flex flex-wrap gap-1"><div class="inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]">Block Sparse Recovery</div><div class="inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]">Cooperative Coevolutionary</div><div class="inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]">List-inquiry Evaluation</div><div class="inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]">Multiobjective Problem (MOP)</div></div></div><div class="flex items-center pt-2 px-2 pb-2"><div class="flex flex-row flex-wrap items-start gap-1"><a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/10092910"><div class="items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80 flex gap-2 px-2 py-1 text-[10px]"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-globe size-3"><circle cx="12" cy="12" r="10"></circle><path d="M12 2a14.5 14.5 0 0 0 0 20 14.5 14.5 0 0 0 0-20"></path><path d="M2 12h20"></path></svg>Website</div></a></div></div></div></div><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><div class="rounded-lg bg-card text-card-foreground flex flex-col overflow-hidden border hover:shadow-lg transition-all duration-300 ease-out h-full"><a class="block cursor-pointer" href="https://ieeexplore.ieee.org/document/9892237"><img alt="Evolutionary Multitasking CNN Architecture Search for Hyperspectral Image Classification" loading="lazy" width="500" height="300" decoding="async" data-nimg="1" class="h-40 w-full overflow-hidden object-cover object-top" style="color:transparent" src="/ijcnn.png"/></a><div class="flex flex-col px-2"><div class="space-y-1"><h3 class="font-semibold tracking-tight mt-1 text-base">Evolutionary Multitasking CNN Architecture Search for Hyperspectral Image Classification</h3><time class="font-sans text-xs">Y. Liu, H. Li, M. Gong, et al.</time><div class="hidden font-sans text-xs underline print:visible"></div><div class="prose max-w-full text-pretty font-sans text-xs text-muted-foreground dark:prose-invert"><p>An evolutionary multitasking framework searches CNN architectures for hyperspectral image classification by leveraging task similarity and implicit parallelism. <a href="https://ieeexplore.ieee.org/xpl/conhome/9891857/proceeding">International Joint Conference on Neural Networks (IJCNN), 2022.</a></p></div></div></div><div class="text-pretty font-sans text-sm text-muted-foreground mt-auto flex flex-col px-2"><div class="mt-2 flex flex-wrap gap-1"><div class="inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]">Evolutionary Multitasking</div><div class="inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]">CNN Architecture Search</div><div class="inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]">Hyperspectral Image Classification</div><div class="inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]">Implicit Parallelism</div></div></div><div class="flex items-center pt-2 px-2 pb-2"><div class="flex flex-row flex-wrap items-start gap-1"><a target="_blank" href="https://ieeexplore.ieee.org/document/9892237"><div class="items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80 flex gap-2 px-2 py-1 text-[10px]"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-globe size-3"><circle cx="12" cy="12" r="10"></circle><path d="M12 2a14.5 14.5 0 0 0 0 20 14.5 14.5 0 0 0 0-20"></path><path d="M2 12h20"></path></svg>Website</div></a></div></div></div></div><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><div class="rounded-lg bg-card text-card-foreground flex flex-col overflow-hidden border hover:shadow-lg transition-all duration-300 ease-out h-full"><a class="block cursor-pointer" href="https://doi.org/10.3390/rs14040892"><img alt="An Adaptive Surrogate-Assisted Endmember Extraction Framework Based on Intelligent Optimization Algorithms for Hyperspectral Remote Sensing Images" loading="lazy" width="500" height="300" decoding="async" data-nimg="1" class="h-40 w-full overflow-hidden object-cover object-top" style="color:transparent" src="/RS_paper.png"/></a><div class="flex flex-col px-2"><div class="space-y-1"><h3 class="font-semibold tracking-tight mt-1 text-base">An Adaptive Surrogate-Assisted Endmember Extraction Framework Based on Intelligent Optimization Algorithms for Hyperspectral Remote Sensing Images</h3><time class="font-sans text-xs">Z. Wang, J. Li, Y. Liu, et al.</time><div class="hidden font-sans text-xs underline print:visible"></div><div class="prose max-w-full text-pretty font-sans text-xs text-muted-foreground dark:prose-invert"><p>An adaptive surrogate-assisted framework integrates heuristic optimization algorithms to alleviate computational cost in hyperspectral endmember extraction. <a href="https://www.mdpi.com/journal/remotesensing">Remote Sensing</a>, 2022.</p></div></div></div><div class="text-pretty font-sans text-sm text-muted-foreground mt-auto flex flex-col px-2"><div class="mt-2 flex flex-wrap gap-1"><div class="inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]">Hyperspectral Remote Sensing</div><div class="inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]">Intelligent Optimization Algorithms</div><div class="inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]">Endmember Extraction</div><div class="inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]">Surrogate-Assisted Model</div></div></div><div class="flex items-center pt-2 px-2 pb-2"><div class="flex flex-row flex-wrap items-start gap-1"><a target="_blank" href="https://doi.org/10.3390/rs14040892"><div class="items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80 flex gap-2 px-2 py-1 text-[10px]"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-globe size-3"><circle cx="12" cy="12" r="10"></circle><path d="M12 2a14.5 14.5 0 0 0 0 20 14.5 14.5 0 0 0 0-20"></path><path d="M2 12h20"></path></svg>Website</div></a></div></div></div></div><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><div class="rounded-lg bg-card text-card-foreground flex flex-col overflow-hidden border hover:shadow-lg transition-all duration-300 ease-out h-full"><a class="block cursor-pointer" href="https://www.sciencedirect.com/science/article/pii/S1568494621006347"><img alt="Multi-fidelity evolutionary multitasking optimization for hyperspectral endmember extraction" loading="lazy" width="500" height="300" decoding="async" data-nimg="1" class="h-40 w-full overflow-hidden object-cover object-top" style="color:transparent" src="/ASC_paper.png"/></a><div class="flex flex-col px-2"><div class="space-y-1"><h3 class="font-semibold tracking-tight mt-1 text-base">Multi-fidelity evolutionary multitasking optimization for hyperspectral endmember extraction</h3><time class="font-sans text-xs">J. Li, H. Li, Y. Liu, et al.</time><div class="hidden font-sans text-xs underline print:visible"></div><div class="prose max-w-full text-pretty font-sans text-xs text-muted-foreground dark:prose-invert"><p>A multi-fidelity multitasking optimization framework uses surrogate models for collaborative learning across fidelity levels, reducing evaluation overhead. <a href="https://www.sciencedirect.com/journal/applied-soft-computing">Applied Soft Computing</a>, 2021.</p></div></div></div><div class="text-pretty font-sans text-sm text-muted-foreground mt-auto flex flex-col px-2"><div class="mt-2 flex flex-wrap gap-1"><div class="inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]">Evolutionary Multitasking</div><div class="inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]">Endmember Extraction</div><div class="inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]">Multi-fidelity</div><div class="inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]">Surrogate Model</div></div></div><div class="flex items-center pt-2 px-2 pb-2"><div class="flex flex-row flex-wrap items-start gap-1"><a target="_blank" href="https://www.sciencedirect.com/science/article/pii/S1568494621006347"><div class="items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80 flex gap-2 px-2 py-1 text-[10px]"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-globe size-3"><circle cx="12" cy="12" r="10"></circle><path d="M12 2a14.5 14.5 0 0 0 0 20 14.5 14.5 0 0 0 0-20"></path><path d="M2 12h20"></path></svg>Website</div></a></div></div></div></div><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><div class="rounded-lg bg-card text-card-foreground flex flex-col overflow-hidden border hover:shadow-lg transition-all duration-300 ease-out h-full"><a class="block cursor-pointer" href="#"><img alt="Multiobjective Coevolutionary Bayesian Learning for Hyperspectral Sparse Unmixing" loading="lazy" width="500" height="300" decoding="async" data-nimg="1" class="h-40 w-full overflow-hidden object-cover object-top" style="color:transparent" src="/MCBL.png"/></a><div class="flex flex-col px-2"><div class="space-y-1"><h3 class="font-semibold tracking-tight mt-1 text-base">Multiobjective Coevolutionary Bayesian Learning for Hyperspectral Sparse Unmixing</h3><time class="font-sans text-xs">Y. Liu, et al.</time><div class="hidden font-sans text-xs underline print:visible"></div><div class="prose max-w-full text-pretty font-sans text-xs text-muted-foreground dark:prose-invert"><p>A coevolutionary Bayesian learning mechanism models row-sparsity in abundance matrices and guides sparse unmixing through Bayesian inference. Under review.</p></div></div></div><div class="text-pretty font-sans text-sm text-muted-foreground mt-auto flex flex-col px-2"><div class="mt-2 flex flex-wrap gap-1"><div class="inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]">Sparse Unmixing</div><div class="inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]">Evolutionary Multiobjective Optimization</div><div class="inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]">Cooperative Coevolution</div><div class="inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]">Sparse Bayesian Learning</div></div></div><div class="flex items-center pt-2 px-2 pb-2"></div></div></div><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><div class="rounded-lg bg-card text-card-foreground flex flex-col overflow-hidden border hover:shadow-lg transition-all duration-300 ease-out h-full"><a class="block cursor-pointer" href="#"><img alt="A Multi-level Collaborative Multi-task Sparse Learning Framework and Case Study" loading="lazy" width="500" height="300" decoding="async" data-nimg="1" class="h-40 w-full overflow-hidden object-cover object-top" style="color:transparent" src="/CS2E.png"/></a><div class="flex flex-col px-2"><div class="space-y-1"><h3 class="font-semibold tracking-tight mt-1 text-base">A Multi-level Collaborative Multi-task Sparse Learning Framework and Case Study</h3><time class="font-sans text-xs">Y. Liu, et al.</time><div class="hidden font-sans text-xs underline print:visible"></div><div class="prose max-w-full text-pretty font-sans text-xs text-muted-foreground dark:prose-invert"><p>A multi-level collaborative multitask sparse learning framework combines internal parameter sharing with evolutionary search for auxiliary task configurations. In progress.</p></div></div></div><div class="text-pretty font-sans text-sm text-muted-foreground mt-auto flex flex-col px-2"><div class="mt-2 flex flex-wrap gap-1"><div class="inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]">Multi-task Learning</div><div class="inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]">Sparse Learning</div><div class="inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]">Denoise</div><div class="inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]">Sparse Reconstruction</div></div></div><div class="flex items-center pt-2 px-2 pb-2"></div></div></div></div></div></section><section id="Projects"><div class="space-y-12 w-full py-12"><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><div class="flex flex-col items-center justify-center space-y-4 text-center"><div class="space-y-2"><div class="inline-block rounded-lg bg-foreground text-background px-3 py-1 text-sm">Projects</div><h2 class="text-3xl font-bold tracking-tighter sm:text-5xl">Applied Research Experience</h2><p class="text-muted-foreground md:text-xl/relaxed lg:text-base/relaxed xl:text-xl/relaxed">During my graduate studies, I participated in several research projects involving target detection, neural architecture optimization, and bio-inspired computing. These projects enabled me to explore the intersection of machine learning and evolutionary algorithms, implement scalable model architectures, and contribute to industrial collaborations.</p></div></div></div><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><ul class="mb-4 ml-4 divide-y divide-dashed border-l"><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><li class="relative ml-10 py-4"><div class="absolute -left-16 top-2 flex items-center justify-center bg-white rounded-full"><span class="relative flex shrink-0 overflow-hidden rounded-full border size-12 m-auto"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">T</span></span></div><div class="flex flex-1 flex-col justify-start gap-1"><time class="text-xs text-muted-foreground">Sep 2023 â€“ Mar 2025</time><h2 class="font-semibold leading-none">Target Detection and Recognition Research</h2><p class="text-sm text-muted-foreground">Xi&#x27;an, China</p><span class="prose dark:prose-invert text-sm text-muted-foreground">Developed high-fidelity virtual environments for dataset generation; Improved robustness under varied conditions.</span></div></li></div><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><li class="relative ml-10 py-4"><div class="absolute -left-16 top-2 flex items-center justify-center bg-white rounded-full"><span class="relative flex shrink-0 overflow-hidden rounded-full border size-12 m-auto"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">B</span></span></div><div class="flex flex-1 flex-col justify-start gap-1"><time class="text-xs text-muted-foreground">Jun 2022 â€“ Jan 2023</time><h2 class="font-semibold leading-none">Biological Computing Model Suite (Huawei)</h2><p class="text-sm text-muted-foreground">Xi&#x27;an, China</p><span class="prose dark:prose-invert text-sm text-muted-foreground">Developed models using MindSpore; Achievements integrated into Huawei&#x27;s standard library.</span></div></li></div><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><li class="relative ml-10 py-4"><div class="absolute -left-16 top-2 flex items-center justify-center bg-white rounded-full"><span class="relative flex shrink-0 overflow-hidden rounded-full border size-12 m-auto"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">N</span></span></div><div class="flex flex-1 flex-col justify-start gap-1"><time class="text-xs text-muted-foreground">Sep 2023 â€“ Sep 2024</time><h2 class="font-semibold leading-none">NSFC Key Program: Collaborative Learning and Optimization</h2><p class="text-sm text-muted-foreground">Xi&#x27;an, China</p><span class="prose dark:prose-invert text-sm text-muted-foreground">Integrated deep learning and evolutionary optimization for improving neural network performance and interpretability.</span></div></li></div></ul></div></div></section><section id="contact"><div class="grid items-center justify-center gap-4 px-4 text-center md:px-6 w-full py-12"><div style="opacity:0;filter:blur(6px);transform:translateY(6px)"><div class="space-y-3"><div class="inline-block rounded-lg bg-foreground text-background px-3 py-1 text-sm">Contact</div><h2 class="text-3xl font-bold tracking-tighter sm:text-5xl">Get in Touch</h2><p class="mx-auto max-w-[600px] text-muted-foreground md:text-xl/relaxed lg:text-base/relaxed xl:text-xl/relaxed">If you have any questions, feel free to contact me at <!-- --> <a class="text-blue-500 hover:underline" href="mailto:lyting71@gmail.com">lyting71@gmail.com</a> <!-- -->and I&#x27;ll respond whenever I can.</p></div></div></div></section></main><div class="pointer-events-none fixed inset-x-0 bottom-0 z-30 mx-auto mb-4 flex origin-bottom h-full max-h-14"><div class="fixed bottom-0 inset-x-0 h-16 w-full bg-background to-transparent backdrop-blur-lg [-webkit-mask-image:linear-gradient(to_top,black,transparent)] dark:bg-background"></div><div class="w-max p-2 rounded-full border z-50 pointer-events-auto relative mx-auto flex min-h-full h-full items-center px-1 bg-background [box-shadow:0_0_0_1px_rgba(0,0,0,.03),0_2px_4px_rgba(0,0,0,.05),0_12px_24px_rgba(0,0,0,.05)] transform-gpu dark:[border:1px_solid_rgba(255,255,255,.1)] dark:[box-shadow:0_-20px_80px_-20px_#ffffff1f_inset]"><div class="flex aspect-square cursor-pointer items-center justify-center rounded-full" style="width:40px"><a class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50 hover:bg-accent hover:text-accent-foreground rounded-full size-12" data-state="closed" href="/"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-home size-4"><path d="m3 9 9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"></path><polyline points="9 22 9 12 15 12 15 22"></polyline></svg></a></div><div class="flex aspect-square cursor-pointer items-center justify-center rounded-full" style="width:40px"><a class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50 hover:bg-accent hover:text-accent-foreground rounded-full size-12" data-state="closed" href="/blog"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-notebook size-4"><path d="M2 6h4"></path><path d="M2 10h4"></path><path d="M2 14h4"></path><path d="M2 18h4"></path><rect width="16" height="20" x="4" y="2" rx="2"></rect><path d="M16 2v20"></path></svg></a></div><div data-orientation="vertical" role="none" class="shrink-0 bg-border w-[1px] h-full" mousex="[object Object]" magnification="60" distance="140"></div><div class="flex aspect-square cursor-pointer items-center justify-center rounded-full" style="width:40px"><a class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50 hover:bg-accent hover:text-accent-foreground rounded-full size-12" data-state="closed" href="https://github.com/lyt71"><svg viewBox="0 0 438.549 438.549" class="size-4"><path fill="currentColor" d="M409.132 114.573c-19.608-33.596-46.205-60.194-79.798-79.8-33.598-19.607-70.277-29.408-110.063-29.408-39.781 0-76.472 9.804-110.063 29.408-33.596 19.605-60.192 46.204-79.8 79.8C9.803 148.168 0 184.854 0 224.63c0 47.78 13.94 90.745 41.827 128.906 27.884 38.164 63.906 64.572 108.063 79.227 5.14.954 8.945.283 11.419-1.996 2.475-2.282 3.711-5.14 3.711-8.562 0-.571-.049-5.708-.144-15.417a2549.81 2549.81 0 01-.144-25.406l-6.567 1.136c-4.187.767-9.469 1.092-15.846 1-6.374-.089-12.991-.757-19.842-1.999-6.854-1.231-13.229-4.086-19.13-8.559-5.898-4.473-10.085-10.328-12.56-17.556l-2.855-6.57c-1.903-4.374-4.899-9.233-8.992-14.559-4.093-5.331-8.232-8.945-12.419-10.848l-1.999-1.431c-1.332-.951-2.568-2.098-3.711-3.429-1.142-1.331-1.997-2.663-2.568-3.997-.572-1.335-.098-2.43 1.427-3.289 1.525-.859 4.281-1.276 8.28-1.276l5.708.853c3.807.763 8.516 3.042 14.133 6.851 5.614 3.806 10.229 8.754 13.846 14.842 4.38 7.806 9.657 13.754 15.846 17.847 6.184 4.093 12.419 6.136 18.699 6.136 6.28 0 11.704-.476 16.274-1.423 4.565-.952 8.848-2.383 12.847-4.285 1.713-12.758 6.377-22.559 13.988-29.41-10.848-1.14-20.601-2.857-29.264-5.14-8.658-2.286-17.605-5.996-26.835-11.14-9.235-5.137-16.896-11.516-22.985-19.126-6.09-7.614-11.088-17.61-14.987-29.979-3.901-12.374-5.852-26.648-5.852-42.826 0-23.035 7.52-42.637 22.557-58.817-7.044-17.318-6.379-36.732 1.997-58.24 5.52-1.715 13.706-.428 24.554 3.853 10.85 4.283 18.794 7.952 23.84 10.994 5.046 3.041 9.089 5.618 12.135 7.708 17.705-4.947 35.976-7.421 54.818-7.421s37.117 2.474 54.823 7.421l10.849-6.849c7.419-4.57 16.18-8.758 26.262-12.565 10.088-3.805 17.802-4.853 23.134-3.138 8.562 21.509 9.325 40.922 2.279 58.24 15.036 16.18 22.559 35.787 22.559 58.817 0 16.178-1.958 30.497-5.853 42.966-3.9 12.471-8.941 22.457-15.125 29.979-6.191 7.521-13.901 13.85-23.131 18.986-9.232 5.14-18.182 8.85-26.84 11.136-8.662 2.286-18.415 4.004-29.263 5.146 9.894 8.562 14.842 22.077 14.842 40.539v60.237c0 3.422 1.19 6.279 3.572 8.562 2.379 2.279 6.136 2.95 11.276 1.995 44.163-14.653 80.185-41.062 108.068-79.226 27.88-38.161 41.825-81.126 41.825-128.906-.01-39.771-9.818-76.454-29.414-110.049z"></path></svg></a></div><div class="flex aspect-square cursor-pointer items-center justify-center rounded-full" style="width:40px"><a class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50 hover:bg-accent hover:text-accent-foreground rounded-full size-12" data-state="closed" href="mailto:lyting71@gmail.com"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-mail size-4"><rect width="20" height="16" x="2" y="4" rx="2"></rect><path d="m22 7-8.97 5.7a1.94 1.94 0 0 1-2.06 0L2 7"></path></svg></a></div><div class="flex aspect-square cursor-pointer items-center justify-center rounded-full" style="width:40px"><a class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50 hover:bg-accent hover:text-accent-foreground rounded-full size-12" data-state="closed" href="/Yiting_Liu_CV.pdf"><svg viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="size-4"><title>CV</title><path d="M4 2a2 2 0 0 0-2 2v16c0 1.1.9 2 2 2h16a2 2 0 0 0 2-2V8l-6-6H4zm13 1.5L20.5 7H17a2 2 0 0 1-2-2V3.5z"></path></svg></a></div><div data-orientation="vertical" role="none" class="shrink-0 bg-border w-[1px] h-full py-2" mousex="[object Object]" magnification="60" distance="140"></div><div class="flex aspect-square cursor-pointer items-center justify-center rounded-full" style="width:40px"><button class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50 hover:bg-accent hover:text-accent-foreground h-9 w-9 rounded-full px-2" type="button"><svg width="15" height="15" viewBox="0 0 15 15" fill="none" xmlns="http://www.w3.org/2000/svg" class="h-[1.2rem] w-[1.2rem] text-neutral-800 dark:hidden dark:text-neutral-200"><path d="M7.5 0C7.77614 0 8 0.223858 8 0.5V2.5C8 2.77614 7.77614 3 7.5 3C7.22386 3 7 2.77614 7 2.5V0.5C7 0.223858 7.22386 0 7.5 0ZM2.1967 2.1967C2.39196 2.00144 2.70854 2.00144 2.90381 2.1967L4.31802 3.61091C4.51328 3.80617 4.51328 4.12276 4.31802 4.31802C4.12276 4.51328 3.80617 4.51328 3.61091 4.31802L2.1967 2.90381C2.00144 2.70854 2.00144 2.39196 2.1967 2.1967ZM0.5 7C0.223858 7 0 7.22386 0 7.5C0 7.77614 0.223858 8 0.5 8H2.5C2.77614 8 3 7.77614 3 7.5C3 7.22386 2.77614 7 2.5 7H0.5ZM2.1967 12.8033C2.00144 12.608 2.00144 12.2915 2.1967 12.0962L3.61091 10.682C3.80617 10.4867 4.12276 10.4867 4.31802 10.682C4.51328 10.8772 4.51328 11.1938 4.31802 11.3891L2.90381 12.8033C2.70854 12.9986 2.39196 12.9986 2.1967 12.8033ZM12.5 7C12.2239 7 12 7.22386 12 7.5C12 7.77614 12.2239 8 12.5 8H14.5C14.7761 8 15 7.77614 15 7.5C15 7.22386 14.7761 7 14.5 7H12.5ZM10.682 4.31802C10.4867 4.12276 10.4867 3.80617 10.682 3.61091L12.0962 2.1967C12.2915 2.00144 12.608 2.00144 12.8033 2.1967C12.9986 2.39196 12.9986 2.70854 12.8033 2.90381L11.3891 4.31802C11.1938 4.51328 10.8772 4.51328 10.682 4.31802ZM8 12.5C8 12.2239 7.77614 12 7.5 12C7.22386 12 7 12.2239 7 12.5V14.5C7 14.7761 7.22386 15 7.5 15C7.77614 15 8 14.7761 8 14.5V12.5ZM10.682 10.682C10.8772 10.4867 11.1938 10.4867 11.3891 10.682L12.8033 12.0962C12.9986 12.2915 12.9986 12.608 12.8033 12.8033C12.608 12.9986 12.2915 12.9986 12.0962 12.8033L10.682 11.3891C10.4867 11.1938 10.4867 10.8772 10.682 10.682ZM5.5 7.5C5.5 6.39543 6.39543 5.5 7.5 5.5C8.60457 5.5 9.5 6.39543 9.5 7.5C9.5 8.60457 8.60457 9.5 7.5 9.5C6.39543 9.5 5.5 8.60457 5.5 7.5ZM7.5 4.5C5.84315 4.5 4.5 5.84315 4.5 7.5C4.5 9.15685 5.84315 10.5 7.5 10.5C9.15685 10.5 10.5 9.15685 10.5 7.5C10.5 5.84315 9.15685 4.5 7.5 4.5Z" fill="currentColor" fill-rule="evenodd" clip-rule="evenodd"></path></svg><svg width="15" height="15" viewBox="0 0 15 15" fill="none" xmlns="http://www.w3.org/2000/svg" class="hidden h-[1.2rem] w-[1.2rem] text-neutral-800 dark:block dark:text-neutral-200"><path d="M2.89998 0.499976C2.89998 0.279062 2.72089 0.0999756 2.49998 0.0999756C2.27906 0.0999756 2.09998 0.279062 2.09998 0.499976V1.09998H1.49998C1.27906 1.09998 1.09998 1.27906 1.09998 1.49998C1.09998 1.72089 1.27906 1.89998 1.49998 1.89998H2.09998V2.49998C2.09998 2.72089 2.27906 2.89998 2.49998 2.89998C2.72089 2.89998 2.89998 2.72089 2.89998 2.49998V1.89998H3.49998C3.72089 1.89998 3.89998 1.72089 3.89998 1.49998C3.89998 1.27906 3.72089 1.09998 3.49998 1.09998H2.89998V0.499976ZM5.89998 3.49998C5.89998 3.27906 5.72089 3.09998 5.49998 3.09998C5.27906 3.09998 5.09998 3.27906 5.09998 3.49998V4.09998H4.49998C4.27906 4.09998 4.09998 4.27906 4.09998 4.49998C4.09998 4.72089 4.27906 4.89998 4.49998 4.89998H5.09998V5.49998C5.09998 5.72089 5.27906 5.89998 5.49998 5.89998C5.72089 5.89998 5.89998 5.72089 5.89998 5.49998V4.89998H6.49998C6.72089 4.89998 6.89998 4.72089 6.89998 4.49998C6.89998 4.27906 6.72089 4.09998 6.49998 4.09998H5.89998V3.49998ZM1.89998 6.49998C1.89998 6.27906 1.72089 6.09998 1.49998 6.09998C1.27906 6.09998 1.09998 6.27906 1.09998 6.49998V7.09998H0.499976C0.279062 7.09998 0.0999756 7.27906 0.0999756 7.49998C0.0999756 7.72089 0.279062 7.89998 0.499976 7.89998H1.09998V8.49998C1.09998 8.72089 1.27906 8.89997 1.49998 8.89997C1.72089 8.89997 1.89998 8.72089 1.89998 8.49998V7.89998H2.49998C2.72089 7.89998 2.89998 7.72089 2.89998 7.49998C2.89998 7.27906 2.72089 7.09998 2.49998 7.09998H1.89998V6.49998ZM8.54406 0.98184L8.24618 0.941586C8.03275 0.917676 7.90692 1.1655 8.02936 1.34194C8.17013 1.54479 8.29981 1.75592 8.41754 1.97445C8.91878 2.90485 9.20322 3.96932 9.20322 5.10022C9.20322 8.37201 6.82247 11.0878 3.69887 11.6097C3.45736 11.65 3.20988 11.6772 2.96008 11.6906C2.74563 11.702 2.62729 11.9535 2.77721 12.1072C2.84551 12.1773 2.91535 12.2458 2.98667 12.3128L3.05883 12.3795L3.31883 12.6045L3.50684 12.7532L3.62796 12.8433L3.81491 12.9742L3.99079 13.089C4.11175 13.1651 4.23536 13.2375 4.36157 13.3059L4.62496 13.4412L4.88553 13.5607L5.18837 13.6828L5.43169 13.7686C5.56564 13.8128 5.70149 13.8529 5.83857 13.8885C5.94262 13.9155 6.04767 13.9401 6.15405 13.9622C6.27993 13.9883 6.40713 14.0109 6.53544 14.0298L6.85241 14.0685L7.11934 14.0892C7.24637 14.0965 7.37436 14.1002 7.50322 14.1002C11.1483 14.1002 14.1032 11.1453 14.1032 7.50023C14.1032 7.25044 14.0893 7.00389 14.0623 6.76131L14.0255 6.48407C13.991 6.26083 13.9453 6.04129 13.8891 5.82642C13.8213 5.56709 13.7382 5.31398 13.6409 5.06881L13.5279 4.80132L13.4507 4.63542L13.3766 4.48666C13.2178 4.17773 13.0353 3.88295 12.8312 3.60423L12.6782 3.40352L12.4793 3.16432L12.3157 2.98361L12.1961 2.85951L12.0355 2.70246L11.8134 2.50184L11.4925 2.24191L11.2483 2.06498L10.9562 1.87446L10.6346 1.68894L10.3073 1.52378L10.1938 1.47176L9.95488 1.3706L9.67791 1.2669L9.42566 1.1846L9.10075 1.09489L8.83599 1.03486L8.54406 0.98184ZM10.4032 5.30023C10.4032 4.27588 10.2002 3.29829 9.83244 2.40604C11.7623 3.28995 13.1032 5.23862 13.1032 7.50023C13.1032 10.593 10.596 13.1002 7.50322 13.1002C6.63646 13.1002 5.81597 12.9036 5.08355 12.5522C6.5419 12.0941 7.81081 11.2082 8.74322 10.0416C8.87963 10.2284 9.10028 10.3497 9.34928 10.3497C9.76349 10.3497 10.0993 10.0139 10.0993 9.59971C10.0993 9.24256 9.84965 8.94373 9.51535 8.86816C9.57741 8.75165 9.63653 8.63334 9.6926 8.51332C9.88358 8.63163 10.1088 8.69993 10.35 8.69993C11.0403 8.69993 11.6 8.14028 11.6 7.44993C11.6 6.75976 11.0406 6.20024 10.3505 6.19993C10.3853 5.90487 10.4032 5.60464 10.4032 5.30023Z" fill="currentColor" fill-rule="evenodd" clip-rule="evenodd"></path></svg></button></div></div></div><script src="/_next/static/chunks/webpack-fd9cee151a2f9132.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/css/1e83ba7336cc88b6.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"2:I[5751,[],\"\"]\n4:I[4660,[\"548\",\"static/chunks/548-510bb30c9b0bc6ca.js\",\"742\",\"static/chunks/742-7023ff07d49000d3.js\",\"737\",\"static/chunks/737-b831f966e0626836.js\",\"931\",\"static/chunks/app/page-7128724577c3be1a.js\"],\"default\"]\n5:I[6764,[\"548\",\"static/chunks/548-510bb30c9b0bc6ca.js\",\"742\",\"static/chunks/742-7023ff07d49000d3.js\",\"737\",\"static/chunks/737-b831f966e0626836.js\",\"931\",\"static/chunks/app/page-7128724577c3be1a.js\"],\"default\"]\n6:I[420,[\"548\",\"static/chunks/548-510bb30c9b0bc6ca.js\",\"742\",\"static/chunks/742-7023ff07d49000d3.js\",\"737\",\"static/chunks/737-b831f966e0626836.js\",\"931\",\"static/chunks/app/page-7128724577c3be1a.js\"],\"Avatar\"]\n7:I[420,[\"548\",\"static/chunks/548-510bb30c9b0bc6ca.js\",\"742\",\"static/chunks/742-7023ff07d49000d3.js\",\"737\",\"static/chunks/737-b831f966e0626836.js\",\"931\",\"static/chunks/app/page-7128724577c3be1a.js\"],\"AvatarImage\"]\n8:I[420,[\"548\",\"static/chunks/548-510bb30c9b0bc6ca.js\",\"742\",\"static/chunks/742-7023ff07d49000d3.js\",\"737\",\"static/chunks/737-b831f966e0626836.js\",\"931\",\"static/chunks/app/page-7128724577c3be1a.js\"],\"AvatarFallback\"]\n9:I[6239,[\"548\",\"static/chunks/548-510bb30c9b0bc6ca.js\",\"742\",\"static/chunks/742-7023ff07d49000d3.js\",\"737\",\"static/chunks/737-b831f966e0626836.js\",\"931\",\"static/chunks/app/page-7128724577c3be1a.js\"],\"ResumeCard\"]\na:I[231,[\"548\",\"static/chunks/548-510bb30c9b0bc6ca.js\",\"742\",\"static/chunks/742-7023ff07d49000d3.js\",\"737\",\"static/chunks/737-b831f966e0626836.js\",\"931\",\"static/chunks/app/page-7128724577c3be1a.js\"],\"\"]\nb:I[8173,[\"548\",\"static/chunks/548-510bb30c9b0bc6ca.js\",\"742\",\"static/chunks/742-7023ff07d49000d3.js\",\"737\",\"static/chunks/737-b831f966e0626836.js\",\"931\",\"static/chunks/app/page-7128724577c3be1a.js\"],\"Image\"]\nc:I[4858,[\"310\",\"static/chunks/0e5ce63c-e21fe8bbb1ba0e0f.js\",\"548\",\"static/chunks/548-510bb30c9b0bc6ca.js\",\"742\",\"static/chunks/742-7023ff07d49000d3.js\",\"860\",\"static/chunks/860-f66ad5e413f0575e.js\",\"185\",\"static/chunks/app/layout-e5a652e031f6cc17.js\"],\"ThemeProvider\"]\nd:I[9736,[\"310\",\"static/chunks/0e5ce63c-e21fe8bbb1ba0e0f.js\",\"548\",\"static"])</script><script>self.__next_f.push([1,"/chunks/548-510bb30c9b0bc6ca.js\",\"742\",\"static/chunks/742-7023ff07d49000d3.js\",\"860\",\"static/chunks/860-f66ad5e413f0575e.js\",\"185\",\"static/chunks/app/layout-e5a652e031f6cc17.js\"],\"TooltipProvider\"]\ne:I[9275,[],\"\"]\nf:I[1343,[],\"\"]\n10:I[6691,[\"310\",\"static/chunks/0e5ce63c-e21fe8bbb1ba0e0f.js\",\"548\",\"static/chunks/548-510bb30c9b0bc6ca.js\",\"742\",\"static/chunks/742-7023ff07d49000d3.js\",\"860\",\"static/chunks/860-f66ad5e413f0575e.js\",\"185\",\"static/chunks/app/layout-e5a652e031f6cc17.js\"],\"Dock\"]\n11:I[6691,[\"310\",\"static/chunks/0e5ce63c-e21fe8bbb1ba0e0f.js\",\"548\",\"static/chunks/548-510bb30c9b0bc6ca.js\",\"742\",\"static/chunks/742-7023ff07d49000d3.js\",\"860\",\"static/chunks/860-f66ad5e413f0575e.js\",\"185\",\"static/chunks/app/layout-e5a652e031f6cc17.js\"],\"DockIcon\"]\n12:I[9736,[\"310\",\"static/chunks/0e5ce63c-e21fe8bbb1ba0e0f.js\",\"548\",\"static/chunks/548-510bb30c9b0bc6ca.js\",\"742\",\"static/chunks/742-7023ff07d49000d3.js\",\"860\",\"static/chunks/860-f66ad5e413f0575e.js\",\"185\",\"static/chunks/app/layout-e5a652e031f6cc17.js\"],\"Tooltip\"]\n13:I[9736,[\"310\",\"static/chunks/0e5ce63c-e21fe8bbb1ba0e0f.js\",\"548\",\"static/chunks/548-510bb30c9b0bc6ca.js\",\"742\",\"static/chunks/742-7023ff07d49000d3.js\",\"860\",\"static/chunks/860-f66ad5e413f0575e.js\",\"185\",\"static/chunks/app/layout-e5a652e031f6cc17.js\"],\"TooltipTrigger\"]\n14:I[9736,[\"310\",\"static/chunks/0e5ce63c-e21fe8bbb1ba0e0f.js\",\"548\",\"static/chunks/548-510bb30c9b0bc6ca.js\",\"742\",\"static/chunks/742-7023ff07d49000d3.js\",\"860\",\"static/chunks/860-f66ad5e413f0575e.js\",\"185\",\"static/chunks/app/layout-e5a652e031f6cc17.js\"],\"TooltipContent\"]\n15:I[9973,[\"310\",\"static/chunks/0e5ce63c-e21fe8bbb1ba0e0f.js\",\"548\",\"static/chunks/548-510bb30c9b0bc6ca.js\",\"742\",\"static/chunks/742-7023ff07d49000d3.js\",\"860\",\"static/chunks/860-f66ad5e413f0575e.js\",\"185\",\"static/chunks/app/layout-e5a652e031f6cc17.js\"],\"Separator\"]\n17:I[7363,[\"310\",\"static/chunks/0e5ce63c-e21fe8bbb1ba0e0f.js\",\"548\",\"static/chunks/548-510bb30c9b0bc6ca.js\",\"742\",\"static/chunks/742-7023ff07d49000d3.js\",\"860\",\"static/chunks/860-f66ad5e413f0575e.js\",\"185\",\"static/"])</script><script>self.__next_f.push([1,"chunks/app/layout-e5a652e031f6cc17.js\"],\"ModeToggle\"]\n19:I[6130,[],\"\"]\n16:T843,"])</script><script>self.__next_f.push([1,"M409.132 114.573c-19.608-33.596-46.205-60.194-79.798-79.8-33.598-19.607-70.277-29.408-110.063-29.408-39.781 0-76.472 9.804-110.063 29.408-33.596 19.605-60.192 46.204-79.8 79.8C9.803 148.168 0 184.854 0 224.63c0 47.78 13.94 90.745 41.827 128.906 27.884 38.164 63.906 64.572 108.063 79.227 5.14.954 8.945.283 11.419-1.996 2.475-2.282 3.711-5.14 3.711-8.562 0-.571-.049-5.708-.144-15.417a2549.81 2549.81 0 01-.144-25.406l-6.567 1.136c-4.187.767-9.469 1.092-15.846 1-6.374-.089-12.991-.757-19.842-1.999-6.854-1.231-13.229-4.086-19.13-8.559-5.898-4.473-10.085-10.328-12.56-17.556l-2.855-6.57c-1.903-4.374-4.899-9.233-8.992-14.559-4.093-5.331-8.232-8.945-12.419-10.848l-1.999-1.431c-1.332-.951-2.568-2.098-3.711-3.429-1.142-1.331-1.997-2.663-2.568-3.997-.572-1.335-.098-2.43 1.427-3.289 1.525-.859 4.281-1.276 8.28-1.276l5.708.853c3.807.763 8.516 3.042 14.133 6.851 5.614 3.806 10.229 8.754 13.846 14.842 4.38 7.806 9.657 13.754 15.846 17.847 6.184 4.093 12.419 6.136 18.699 6.136 6.28 0 11.704-.476 16.274-1.423 4.565-.952 8.848-2.383 12.847-4.285 1.713-12.758 6.377-22.559 13.988-29.41-10.848-1.14-20.601-2.857-29.264-5.14-8.658-2.286-17.605-5.996-26.835-11.14-9.235-5.137-16.896-11.516-22.985-19.126-6.09-7.614-11.088-17.61-14.987-29.979-3.901-12.374-5.852-26.648-5.852-42.826 0-23.035 7.52-42.637 22.557-58.817-7.044-17.318-6.379-36.732 1.997-58.24 5.52-1.715 13.706-.428 24.554 3.853 10.85 4.283 18.794 7.952 23.84 10.994 5.046 3.041 9.089 5.618 12.135 7.708 17.705-4.947 35.976-7.421 54.818-7.421s37.117 2.474 54.823 7.421l10.849-6.849c7.419-4.57 16.18-8.758 26.262-12.565 10.088-3.805 17.802-4.853 23.134-3.138 8.562 21.509 9.325 40.922 2.279 58.24 15.036 16.18 22.559 35.787 22.559 58.817 0 16.178-1.958 30.497-5.853 42.966-3.9 12.471-8.941 22.457-15.125 29.979-6.191 7.521-13.901 13.85-23.131 18.986-9.232 5.14-18.182 8.85-26.84 11.136-8.662 2.286-18.415 4.004-29.263 5.146 9.894 8.562 14.842 22.077 14.842 40.539v60.237c0 3.422 1.19 6.279 3.572 8.562 2.379 2.279 6.136 2.95 11.276 1.995 44.163-14.653 80.185-41.062 108.068-79.226 27.88-38.161 41.825-81.126 41.825-128.906-.01-39.771-9.818-76.454-29.414-110.049z"])</script><script>self.__next_f.push([1,"1a:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/1e83ba7336cc88b6.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L2\",null,{\"buildId\":\"eVhIQ5NPLaGoWSK7waHeH\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/\",\"initialTree\":[\"\",{\"children\":[\"__PAGE__\",{}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"__PAGE__\",{},[[\"$L3\",[\"$\",\"main\",null,{\"className\":\"flex flex-col min-h-[100dvh] space-y-10\",\"children\":[[\"$\",\"section\",null,{\"id\":\"hero\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto w-full max-w-2xl space-y-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"gap-2 flex justify-between\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex-col flex flex-1 space-y-1.5\",\"children\":[[\"$\",\"$L4\",null,{\"delay\":0.04,\"className\":\"text-2xl font-bold tracking-tighter sm:text-4xl xl:text-5xl/none\",\"yOffset\":8,\"text\":\"Hi, I'm Yiting Liu ðŸ‘‹\"}],[\"$\",\"$L4\",null,{\"className\":\"max-w-[600px] md:text-xl\",\"delay\":0.04,\"text\":\"Ph.D. Candidate, Control Science and Engineering, Xidian University, Xi'an, China\"}]]}],[\"$\",\"$L5\",null,{\"delay\":0.04,\"children\":[\"$\",\"$L6\",null,{\"className\":\"size-28 border\",\"children\":[[\"$\",\"$L7\",null,{\"alt\":\"Yiting Liu\",\"src\":\"/me.png\"}],[\"$\",\"$L8\",null,{\"children\":\"YT\"}]]}]}]]}]}]}],[\"$\",\"section\",null,{\"id\":\"about\",\"children\":[[\"$\",\"$L5\",null,{\"delay\":0.12,\"children\":[\"$\",\"h2\",null,{\"className\":\"text-xl font-bold\",\"children\":\"About\"}]}],[\"$\",\"$L5\",null,{\"delay\":0.16,\"children\":[\"$\",\"div\",null,{\"className\":\"prose max-w-full text-pretty font-sans text-sm text-muted-foreground dark:prose-invert\",\"children\":[\"$\",\"p\",\"p-0\",{\"children\":\"Welcome to my academic homepage. I am a Ph.D. candidate at Xidian University, focusing on sparse optimization, machine learning, and evolutionary computation. Please explore the different sections to learn more about my research and academic journey.\"}]}]}]]}],[\"$\",\"section\",null,{\"id\":\"education\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex min-h-0 flex-col gap-y-3\",\"children\":[[\"$\",\"$L5\",null,{\"delay\":0.28,\"children\":[\"$\",\"h2\",null,{\"className\":\"text-xl font-bold\",\"children\":\"Education\"}]}],[[\"$\",\"$L5\",\"Xidian University\",{\"delay\":0.32,\"children\":[\"$\",\"$L9\",\"Xidian University\",{\"href\":\"https://www.xidian.edu.cn\",\"logoUrl\":\"/xidian.png\",\"altText\":\"Xidian University\",\"title\":\"Xidian University\",\"subtitle\":\"Ph.D. in Control Science and Engineering\",\"period\":\"2022 - 2025\",\"note\":\"GPA: 95.14/100 (Top 1%)\",\"awards\":\"Awards: Outstanding Doctoral Candidate (2023â€“2024), Outstanding Student (2022â€“2024), Shenglu Scholarship (2024), Ceyear Scholarship (2025)\"}]}],[\"$\",\"$L5\",\"Xidian University\",{\"delay\":0.37,\"children\":[\"$\",\"$L9\",\"Xidian University\",{\"href\":\"https://www.xidian.edu.cn\",\"logoUrl\":\"/xidian.png\",\"altText\":\"Xidian University\",\"title\":\"Xidian University\",\"subtitle\":\"M.S. in Electronic Science and Technology\",\"period\":\"2020 - 2022\",\"note\":\"GPA: 90.64/100 (Top 5%)\",\"awards\":\"Awards: Special Freshman (2020), Outstanding Student (2021), Peng Cheng Lab OpenI Community Excellent Developer (2022)\"}]}],[\"$\",\"$L5\",\"Hunan University\",{\"delay\":0.42000000000000004,\"children\":[\"$\",\"$L9\",\"Hunan University\",{\"href\":\"https://www.hnu.edu.cn\",\"logoUrl\":\"/hunan.png\",\"altText\":\"Hunan University\",\"title\":\"Hunan University\",\"subtitle\":\"B.S. in Electronic Information Engineering\",\"period\":\"2016 - 2020\",\"note\":\"GPA: 85.38/100 (Top 10%)\",\"awards\":\"Awards: Outstanding Student (2017â€“2019)\"}]}]]]}]}],[\"$\",\"section\",null,{\"id\":\"skills\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex min-h-0 flex-col gap-y-3\",\"children\":[[\"$\",\"$L5\",null,{\"delay\":0.36,\"children\":[\"$\",\"h2\",null,{\"className\":\"text-xl font-bold\",\"children\":\"Skills\"}]}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap gap-1\",\"children\":[[\"$\",\"$L5\",\"Python\",{\"delay\":0.4,\"children\":[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80\",\"children\":\"Python\"}]}],[\"$\",\"$L5\",\"Matlab\",{\"delay\":0.45,\"children\":[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80\",\"children\":\"Matlab\"}]}],[\"$\",\"$L5\",\"OpenCV\",{\"delay\":0.5,\"children\":[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80\",\"children\":\"OpenCV\"}]}],[\"$\",\"$L5\",\"PyTorch\",{\"delay\":0.55,\"children\":[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80\",\"children\":\"PyTorch\"}]}],[\"$\",\"$L5\",\"TensorFlow\",{\"delay\":0.6000000000000001,\"children\":[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80\",\"children\":\"TensorFlow\"}]}],[\"$\",\"$L5\",\"NumPy\",{\"delay\":0.65,\"children\":[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80\",\"children\":\"NumPy\"}]}],[\"$\",\"$L5\",\"React\",{\"delay\":0.7000000000000001,\"children\":[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80\",\"children\":\"React\"}]}],[\"$\",\"$L5\",\"Next.js\",{\"delay\":0.75,\"children\":[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80\",\"children\":\"Next.js\"}]}],[\"$\",\"$L5\",\"Typescript\",{\"delay\":0.8,\"children\":[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80\",\"children\":\"Typescript\"}]}],[\"$\",\"$L5\",\"Node.js\",{\"delay\":0.8500000000000001,\"children\":[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80\",\"children\":\"Node.js\"}]}]]}]]}]}],[\"$\",\"section\",null,{\"id\":\"Publications\",\"children\":[\"$\",\"div\",null,{\"className\":\"space-y-12 w-full py-12\",\"children\":[[\"$\",\"$L5\",null,{\"delay\":0.44,\"children\":[\"$\",\"div\",null,{\"className\":\"flex flex-col items-center justify-center space-y-4 text-center\",\"children\":[\"$\",\"div\",null,{\"className\":\"space-y-2\",\"children\":[[\"$\",\"div\",null,{\"className\":\"inline-block rounded-lg bg-foreground text-background px-3 py-1 text-sm\",\"children\":\"Publications\"}],[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold tracking-tighter sm:text-5xl\",\"children\":\"Check out my work\"}],[\"$\",\"p\",null,{\"className\":\"text-muted-foreground md:text-xl/relaxed lg:text-base/relaxed xl:text-xl/relaxed\",\"children\":\"My research focuses on sparse optimization, machine learning, and evolutionary computation. I explore collaborative, data-driven methods in machine learning, using sparse modeling and optimization to improve robustness, efficiency, and interpretability.\"}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"grid grid-cols-1 gap-3 sm:grid-cols-2 max-w-[800px] mx-auto\",\"children\":[[\"$\",\"$L5\",\"Collaborative Self-Supervised Evolution for Few-Shot Remote Sensing Scene Classification\",{\"delay\":0.48,\"children\":[\"$\",\"div\",null,{\"className\":\"rounded-lg bg-card text-card-foreground flex flex-col overflow-hidden border hover:shadow-lg transition-all duration-300 ease-out h-full\",\"children\":[[\"$\",\"$La\",null,{\"href\":\"https://ieeexplore.ieee.org/abstract/document/10613908\",\"className\":\"block cursor-pointer\",\"children\":[\"\",[\"$\",\"$Lb\",null,{\"src\":\"/tgrs_paper.png\",\"alt\":\"Collaborative Self-Supervised Evolution for Few-Shot Remote Sensing Scene Classification\",\"width\":500,\"height\":300,\"className\":\"h-40 w-full overflow-hidden object-cover object-top\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex flex-col px-2\",\"children\":[\"$\",\"div\",null,{\"className\":\"space-y-1\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"font-semibold tracking-tight mt-1 text-base\",\"children\":\"Collaborative Self-Supervised Evolution for Few-Shot Remote Sensing Scene Classification\"}],[\"$\",\"time\",null,{\"className\":\"font-sans text-xs\",\"children\":\"Y. Liu, J. Li, M. Gong, et al.\"}],[\"$\",\"div\",null,{\"className\":\"hidden font-sans text-xs underline print:visible\",\"children\":\"$undefined\"}],[\"$\",\"div\",null,{\"className\":\"prose max-w-full text-pretty font-sans text-xs text-muted-foreground dark:prose-invert\",\"children\":[\"$\",\"p\",\"p-0\",{\"children\":[\"An evolutionary strategy is used to search for optimal auxiliary task combinations to improve few-shot remote sensing scene classification. \",[\"$\",\"a\",\"a-0\",{\"href\":\"https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=36\",\"children\":\"IEEE Transactions on Geoscience and Remote Sensing\"}],\", 2024.\"]}]}]]}]}],[\"$\",\"div\",null,{\"className\":\"text-pretty font-sans text-sm text-muted-foreground mt-auto flex flex-col px-2\",\"children\":[\"$\",\"div\",null,{\"className\":\"mt-2 flex flex-wrap gap-1\",\"children\":[[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]\",\"children\":\"Collaborative Evolution Strategy\"}],[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]\",\"children\":\"Few-shot Learning\"}],[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]\",\"children\":\"Remote Sensing Scene Classification\"}],[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]\",\"children\":\"Self-supervised Learning\"}]]}]}],[\"$\",\"div\",null,{\"className\":\"flex items-center pt-2 px-2 pb-2\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex flex-row flex-wrap items-start gap-1\",\"children\":[[\"$\",\"$La\",\"0\",{\"href\":\"https://ieeexplore.ieee.org/abstract/document/10613908\",\"target\":\"_blank\",\"children\":[\"$\",\"div\",null,{\"className\":\"items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80 flex gap-2 px-2 py-1 text-[10px]\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-globe size-3\",\"children\":[[\"$\",\"circle\",\"1mglay\",{\"cx\":\"12\",\"cy\":\"12\",\"r\":\"10\"}],[\"$\",\"path\",\"13o1zl\",{\"d\":\"M12 2a14.5 14.5 0 0 0 0 20 14.5 14.5 0 0 0 0-20\"}],[\"$\",\"path\",\"9i4pu4\",{\"d\":\"M2 12h20\"}],\"$undefined\"]}],\"Website\"]}]}]]}]}]]}]}],[\"$\",\"$L5\",\"Nonzero Degree-Based Multiobjective Cooperative Coevolutionary for Block Sparse Recovery\",{\"delay\":0.53,\"children\":[\"$\",\"div\",null,{\"className\":\"rounded-lg bg-card text-card-foreground flex flex-col overflow-hidden border hover:shadow-lg transition-all duration-300 ease-out h-full\",\"children\":[[\"$\",\"$La\",null,{\"href\":\"https://ieeexplore.ieee.org/abstract/document/10092910\",\"className\":\"block cursor-pointer\",\"children\":[\"\",[\"$\",\"$Lb\",null,{\"src\":\"/tevc_paper.png\",\"alt\":\"Nonzero Degree-Based Multiobjective Cooperative Coevolutionary for Block Sparse Recovery\",\"width\":500,\"height\":300,\"className\":\"h-40 w-full overflow-hidden object-cover object-top\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex flex-col px-2\",\"children\":[\"$\",\"div\",null,{\"className\":\"space-y-1\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"font-semibold tracking-tight mt-1 text-base\",\"children\":\"Nonzero Degree-Based Multiobjective Cooperative Coevolutionary for Block Sparse Recovery\"}],[\"$\",\"time\",null,{\"className\":\"font-sans text-xs\",\"children\":\"Y. Liu, H. Li, M. Gong, A. K. Qin\"}],[\"$\",\"div\",null,{\"className\":\"hidden font-sans text-xs underline print:visible\",\"children\":\"$undefined\"}],[\"$\",\"div\",null,{\"className\":\"prose max-w-full text-pretty font-sans text-xs text-muted-foreground dark:prose-invert\",\"children\":[\"$\",\"p\",\"p-0\",{\"children\":[\"A multiobjective cooperative coevolutionary method integrates the spatial structure of block sparse signals to reduce search difficulty and improve efficiency. \",[\"$\",\"a\",\"a-0\",{\"href\":\"https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=4235\",\"children\":\"IEEE Transactions on Evolutionary Computation\"}],\", 2024.\"]}]}]]}]}],[\"$\",\"div\",null,{\"className\":\"text-pretty font-sans text-sm text-muted-foreground mt-auto flex flex-col px-2\",\"children\":[\"$\",\"div\",null,{\"className\":\"mt-2 flex flex-wrap gap-1\",\"children\":[[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]\",\"children\":\"Block Sparse Recovery\"}],[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]\",\"children\":\"Cooperative Coevolutionary\"}],[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]\",\"children\":\"List-inquiry Evaluation\"}],[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]\",\"children\":\"Multiobjective Problem (MOP)\"}]]}]}],[\"$\",\"div\",null,{\"className\":\"flex items-center pt-2 px-2 pb-2\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex flex-row flex-wrap items-start gap-1\",\"children\":[[\"$\",\"$La\",\"0\",{\"href\":\"https://ieeexplore.ieee.org/abstract/document/10092910\",\"target\":\"_blank\",\"children\":[\"$\",\"div\",null,{\"className\":\"items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80 flex gap-2 px-2 py-1 text-[10px]\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-globe size-3\",\"children\":[[\"$\",\"circle\",\"1mglay\",{\"cx\":\"12\",\"cy\":\"12\",\"r\":\"10\"}],[\"$\",\"path\",\"13o1zl\",{\"d\":\"M12 2a14.5 14.5 0 0 0 0 20 14.5 14.5 0 0 0 0-20\"}],[\"$\",\"path\",\"9i4pu4\",{\"d\":\"M2 12h20\"}],\"$undefined\"]}],\"Website\"]}]}]]}]}]]}]}],[\"$\",\"$L5\",\"Evolutionary Multitasking CNN Architecture Search for Hyperspectral Image Classification\",{\"delay\":0.58,\"children\":[\"$\",\"div\",null,{\"className\":\"rounded-lg bg-card text-card-foreground flex flex-col overflow-hidden border hover:shadow-lg transition-all duration-300 ease-out h-full\",\"children\":[[\"$\",\"$La\",null,{\"href\":\"https://ieeexplore.ieee.org/document/9892237\",\"className\":\"block cursor-pointer\",\"children\":[\"\",[\"$\",\"$Lb\",null,{\"src\":\"/ijcnn.png\",\"alt\":\"Evolutionary Multitasking CNN Architecture Search for Hyperspectral Image Classification\",\"width\":500,\"height\":300,\"className\":\"h-40 w-full overflow-hidden object-cover object-top\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex flex-col px-2\",\"children\":[\"$\",\"div\",null,{\"className\":\"space-y-1\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"font-semibold tracking-tight mt-1 text-base\",\"children\":\"Evolutionary Multitasking CNN Architecture Search for Hyperspectral Image Classification\"}],[\"$\",\"time\",null,{\"className\":\"font-sans text-xs\",\"children\":\"Y. Liu, H. Li, M. Gong, et al.\"}],[\"$\",\"div\",null,{\"className\":\"hidden font-sans text-xs underline print:visible\",\"children\":\"$undefined\"}],[\"$\",\"div\",null,{\"className\":\"prose max-w-full text-pretty font-sans text-xs text-muted-foreground dark:prose-invert\",\"children\":[\"$\",\"p\",\"p-0\",{\"children\":[\"An evolutionary multitasking framework searches CNN architectures for hyperspectral image classification by leveraging task similarity and implicit parallelism. \",[\"$\",\"a\",\"a-0\",{\"href\":\"https://ieeexplore.ieee.org/xpl/conhome/9891857/proceeding\",\"children\":\"International Joint Conference on Neural Networks (IJCNN), 2022.\"}]]}]}]]}]}],[\"$\",\"div\",null,{\"className\":\"text-pretty font-sans text-sm text-muted-foreground mt-auto flex flex-col px-2\",\"children\":[\"$\",\"div\",null,{\"className\":\"mt-2 flex flex-wrap gap-1\",\"children\":[[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]\",\"children\":\"Evolutionary Multitasking\"}],[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]\",\"children\":\"CNN Architecture Search\"}],[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]\",\"children\":\"Hyperspectral Image Classification\"}],[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]\",\"children\":\"Implicit Parallelism\"}]]}]}],[\"$\",\"div\",null,{\"className\":\"flex items-center pt-2 px-2 pb-2\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex flex-row flex-wrap items-start gap-1\",\"children\":[[\"$\",\"$La\",\"0\",{\"href\":\"https://ieeexplore.ieee.org/document/9892237\",\"target\":\"_blank\",\"children\":[\"$\",\"div\",null,{\"className\":\"items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80 flex gap-2 px-2 py-1 text-[10px]\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-globe size-3\",\"children\":[[\"$\",\"circle\",\"1mglay\",{\"cx\":\"12\",\"cy\":\"12\",\"r\":\"10\"}],[\"$\",\"path\",\"13o1zl\",{\"d\":\"M12 2a14.5 14.5 0 0 0 0 20 14.5 14.5 0 0 0 0-20\"}],[\"$\",\"path\",\"9i4pu4\",{\"d\":\"M2 12h20\"}],\"$undefined\"]}],\"Website\"]}]}]]}]}]]}]}],[\"$\",\"$L5\",\"An Adaptive Surrogate-Assisted Endmember Extraction Framework Based on Intelligent Optimization Algorithms for Hyperspectral Remote Sensing Images\",{\"delay\":0.63,\"children\":[\"$\",\"div\",null,{\"className\":\"rounded-lg bg-card text-card-foreground flex flex-col overflow-hidden border hover:shadow-lg transition-all duration-300 ease-out h-full\",\"children\":[[\"$\",\"$La\",null,{\"href\":\"https://doi.org/10.3390/rs14040892\",\"className\":\"block cursor-pointer\",\"children\":[\"\",[\"$\",\"$Lb\",null,{\"src\":\"/RS_paper.png\",\"alt\":\"An Adaptive Surrogate-Assisted Endmember Extraction Framework Based on Intelligent Optimization Algorithms for Hyperspectral Remote Sensing Images\",\"width\":500,\"height\":300,\"className\":\"h-40 w-full overflow-hidden object-cover object-top\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex flex-col px-2\",\"children\":[\"$\",\"div\",null,{\"className\":\"space-y-1\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"font-semibold tracking-tight mt-1 text-base\",\"children\":\"An Adaptive Surrogate-Assisted Endmember Extraction Framework Based on Intelligent Optimization Algorithms for Hyperspectral Remote Sensing Images\"}],[\"$\",\"time\",null,{\"className\":\"font-sans text-xs\",\"children\":\"Z. Wang, J. Li, Y. Liu, et al.\"}],[\"$\",\"div\",null,{\"className\":\"hidden font-sans text-xs underline print:visible\",\"children\":\"$undefined\"}],[\"$\",\"div\",null,{\"className\":\"prose max-w-full text-pretty font-sans text-xs text-muted-foreground dark:prose-invert\",\"children\":[\"$\",\"p\",\"p-0\",{\"children\":[\"An adaptive surrogate-assisted framework integrates heuristic optimization algorithms to alleviate computational cost in hyperspectral endmember extraction. \",[\"$\",\"a\",\"a-0\",{\"href\":\"https://www.mdpi.com/journal/remotesensing\",\"children\":\"Remote Sensing\"}],\", 2022.\"]}]}]]}]}],[\"$\",\"div\",null,{\"className\":\"text-pretty font-sans text-sm text-muted-foreground mt-auto flex flex-col px-2\",\"children\":[\"$\",\"div\",null,{\"className\":\"mt-2 flex flex-wrap gap-1\",\"children\":[[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]\",\"children\":\"Hyperspectral Remote Sensing\"}],[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]\",\"children\":\"Intelligent Optimization Algorithms\"}],[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]\",\"children\":\"Endmember Extraction\"}],[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]\",\"children\":\"Surrogate-Assisted Model\"}]]}]}],[\"$\",\"div\",null,{\"className\":\"flex items-center pt-2 px-2 pb-2\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex flex-row flex-wrap items-start gap-1\",\"children\":[[\"$\",\"$La\",\"0\",{\"href\":\"https://doi.org/10.3390/rs14040892\",\"target\":\"_blank\",\"children\":[\"$\",\"div\",null,{\"className\":\"items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80 flex gap-2 px-2 py-1 text-[10px]\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-globe size-3\",\"children\":[[\"$\",\"circle\",\"1mglay\",{\"cx\":\"12\",\"cy\":\"12\",\"r\":\"10\"}],[\"$\",\"path\",\"13o1zl\",{\"d\":\"M12 2a14.5 14.5 0 0 0 0 20 14.5 14.5 0 0 0 0-20\"}],[\"$\",\"path\",\"9i4pu4\",{\"d\":\"M2 12h20\"}],\"$undefined\"]}],\"Website\"]}]}]]}]}]]}]}],[\"$\",\"$L5\",\"Multi-fidelity evolutionary multitasking optimization for hyperspectral endmember extraction\",{\"delay\":0.6799999999999999,\"children\":[\"$\",\"div\",null,{\"className\":\"rounded-lg bg-card text-card-foreground flex flex-col overflow-hidden border hover:shadow-lg transition-all duration-300 ease-out h-full\",\"children\":[[\"$\",\"$La\",null,{\"href\":\"https://www.sciencedirect.com/science/article/pii/S1568494621006347\",\"className\":\"block cursor-pointer\",\"children\":[\"\",[\"$\",\"$Lb\",null,{\"src\":\"/ASC_paper.png\",\"alt\":\"Multi-fidelity evolutionary multitasking optimization for hyperspectral endmember extraction\",\"width\":500,\"height\":300,\"className\":\"h-40 w-full overflow-hidden object-cover object-top\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex flex-col px-2\",\"children\":[\"$\",\"div\",null,{\"className\":\"space-y-1\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"font-semibold tracking-tight mt-1 text-base\",\"children\":\"Multi-fidelity evolutionary multitasking optimization for hyperspectral endmember extraction\"}],[\"$\",\"time\",null,{\"className\":\"font-sans text-xs\",\"children\":\"J. Li, H. Li, Y. Liu, et al.\"}],[\"$\",\"div\",null,{\"className\":\"hidden font-sans text-xs underline print:visible\",\"children\":\"$undefined\"}],[\"$\",\"div\",null,{\"className\":\"prose max-w-full text-pretty font-sans text-xs text-muted-foreground dark:prose-invert\",\"children\":[\"$\",\"p\",\"p-0\",{\"children\":[\"A multi-fidelity multitasking optimization framework uses surrogate models for collaborative learning across fidelity levels, reducing evaluation overhead. \",[\"$\",\"a\",\"a-0\",{\"href\":\"https://www.sciencedirect.com/journal/applied-soft-computing\",\"children\":\"Applied Soft Computing\"}],\", 2021.\"]}]}]]}]}],[\"$\",\"div\",null,{\"className\":\"text-pretty font-sans text-sm text-muted-foreground mt-auto flex flex-col px-2\",\"children\":[\"$\",\"div\",null,{\"className\":\"mt-2 flex flex-wrap gap-1\",\"children\":[[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]\",\"children\":\"Evolutionary Multitasking\"}],[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]\",\"children\":\"Endmember Extraction\"}],[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]\",\"children\":\"Multi-fidelity\"}],[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]\",\"children\":\"Surrogate Model\"}]]}]}],[\"$\",\"div\",null,{\"className\":\"flex items-center pt-2 px-2 pb-2\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex flex-row flex-wrap items-start gap-1\",\"children\":[[\"$\",\"$La\",\"0\",{\"href\":\"https://www.sciencedirect.com/science/article/pii/S1568494621006347\",\"target\":\"_blank\",\"children\":[\"$\",\"div\",null,{\"className\":\"items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80 flex gap-2 px-2 py-1 text-[10px]\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-globe size-3\",\"children\":[[\"$\",\"circle\",\"1mglay\",{\"cx\":\"12\",\"cy\":\"12\",\"r\":\"10\"}],[\"$\",\"path\",\"13o1zl\",{\"d\":\"M12 2a14.5 14.5 0 0 0 0 20 14.5 14.5 0 0 0 0-20\"}],[\"$\",\"path\",\"9i4pu4\",{\"d\":\"M2 12h20\"}],\"$undefined\"]}],\"Website\"]}]}]]}]}]]}]}],[\"$\",\"$L5\",\"Multiobjective Coevolutionary Bayesian Learning for Hyperspectral Sparse Unmixing\",{\"delay\":0.73,\"children\":[\"$\",\"div\",null,{\"className\":\"rounded-lg bg-card text-card-foreground flex flex-col overflow-hidden border hover:shadow-lg transition-all duration-300 ease-out h-full\",\"children\":[[\"$\",\"$La\",null,{\"href\":\"#\",\"className\":\"block cursor-pointer\",\"children\":[\"\",[\"$\",\"$Lb\",null,{\"src\":\"/MCBL.png\",\"alt\":\"Multiobjective Coevolutionary Bayesian Learning for Hyperspectral Sparse Unmixing\",\"width\":500,\"height\":300,\"className\":\"h-40 w-full overflow-hidden object-cover object-top\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex flex-col px-2\",\"children\":[\"$\",\"div\",null,{\"className\":\"space-y-1\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"font-semibold tracking-tight mt-1 text-base\",\"children\":\"Multiobjective Coevolutionary Bayesian Learning for Hyperspectral Sparse Unmixing\"}],[\"$\",\"time\",null,{\"className\":\"font-sans text-xs\",\"children\":\"Y. Liu, et al.\"}],[\"$\",\"div\",null,{\"className\":\"hidden font-sans text-xs underline print:visible\",\"children\":\"$undefined\"}],[\"$\",\"div\",null,{\"className\":\"prose max-w-full text-pretty font-sans text-xs text-muted-foreground dark:prose-invert\",\"children\":[\"$\",\"p\",\"p-0\",{\"children\":\"A coevolutionary Bayesian learning mechanism models row-sparsity in abundance matrices and guides sparse unmixing through Bayesian inference. Under review.\"}]}]]}]}],[\"$\",\"div\",null,{\"className\":\"text-pretty font-sans text-sm text-muted-foreground mt-auto flex flex-col px-2\",\"children\":[\"$\",\"div\",null,{\"className\":\"mt-2 flex flex-wrap gap-1\",\"children\":[[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]\",\"children\":\"Sparse Unmixing\"}],[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]\",\"children\":\"Evolutionary Multiobjective Optimization\"}],[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]\",\"children\":\"Cooperative Coevolution\"}],[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]\",\"children\":\"Sparse Bayesian Learning\"}]]}]}],[\"$\",\"div\",null,{\"className\":\"flex items-center pt-2 px-2 pb-2\",\"children\":false}]]}]}],[\"$\",\"$L5\",\"A Multi-level Collaborative Multi-task Sparse Learning Framework and Case Study\",{\"delay\":0.78,\"children\":[\"$\",\"div\",null,{\"className\":\"rounded-lg bg-card text-card-foreground flex flex-col overflow-hidden border hover:shadow-lg transition-all duration-300 ease-out h-full\",\"children\":[[\"$\",\"$La\",null,{\"href\":\"#\",\"className\":\"block cursor-pointer\",\"children\":[\"\",[\"$\",\"$Lb\",null,{\"src\":\"/CS2E.png\",\"alt\":\"A Multi-level Collaborative Multi-task Sparse Learning Framework and Case Study\",\"width\":500,\"height\":300,\"className\":\"h-40 w-full overflow-hidden object-cover object-top\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex flex-col px-2\",\"children\":[\"$\",\"div\",null,{\"className\":\"space-y-1\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"font-semibold tracking-tight mt-1 text-base\",\"children\":\"A Multi-level Collaborative Multi-task Sparse Learning Framework and Case Study\"}],[\"$\",\"time\",null,{\"className\":\"font-sans text-xs\",\"children\":\"Y. Liu, et al.\"}],[\"$\",\"div\",null,{\"className\":\"hidden font-sans text-xs underline print:visible\",\"children\":\"$undefined\"}],[\"$\",\"div\",null,{\"className\":\"prose max-w-full text-pretty font-sans text-xs text-muted-foreground dark:prose-invert\",\"children\":[\"$\",\"p\",\"p-0\",{\"children\":\"A multi-level collaborative multitask sparse learning framework combines internal parameter sharing with evolutionary search for auxiliary task configurations. In progress.\"}]}]]}]}],[\"$\",\"div\",null,{\"className\":\"text-pretty font-sans text-sm text-muted-foreground mt-auto flex flex-col px-2\",\"children\":[\"$\",\"div\",null,{\"className\":\"mt-2 flex flex-wrap gap-1\",\"children\":[[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]\",\"children\":\"Multi-task Learning\"}],[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]\",\"children\":\"Sparse Learning\"}],[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]\",\"children\":\"Denoise\"}],[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-md border font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 px-1 py-0 text-[10px]\",\"children\":\"Sparse Reconstruction\"}]]}]}],[\"$\",\"div\",null,{\"className\":\"flex items-center pt-2 px-2 pb-2\",\"children\":false}]]}]}]]}]]}]}],[\"$\",\"section\",null,{\"id\":\"Projects\",\"children\":[\"$\",\"div\",null,{\"className\":\"space-y-12 w-full py-12\",\"children\":[[\"$\",\"$L5\",null,{\"delay\":0.52,\"children\":[\"$\",\"div\",null,{\"className\":\"flex flex-col items-center justify-center space-y-4 text-center\",\"children\":[\"$\",\"div\",null,{\"className\":\"space-y-2\",\"children\":[[\"$\",\"div\",null,{\"className\":\"inline-block rounded-lg bg-foreground text-background px-3 py-1 text-sm\",\"children\":\"Projects\"}],[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold tracking-tighter sm:text-5xl\",\"children\":\"Applied Research Experience\"}],[\"$\",\"p\",null,{\"className\":\"text-muted-foreground md:text-xl/relaxed lg:text-base/relaxed xl:text-xl/relaxed\",\"children\":\"During my graduate studies, I participated in several research projects involving target detection, neural architecture optimization, and bio-inspired computing. These projects enabled me to explore the intersection of machine learning and evolutionary algorithms, implement scalable model architectures, and contribute to industrial collaborations.\"}]]}]}]}],[\"$\",\"$L5\",null,{\"delay\":0.56,\"children\":[\"$\",\"ul\",null,{\"className\":\"mb-4 ml-4 divide-y divide-dashed border-l\",\"children\":[[\"$\",\"$L5\",\"Target Detection and Recognition ResearchSep 2023 â€“ Mar 2025\",{\"delay\":0.6,\"children\":[\"$\",\"li\",null,{\"className\":\"relative ml-10 py-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"absolute -left-16 top-2 flex items-center justify-center bg-white rounded-full\",\"children\":[\"$\",\"$L6\",null,{\"className\":\"border size-12 m-auto\",\"children\":[[\"$\",\"$L7\",null,{\"src\":\"/ai.jpg\",\"alt\":\"Target Detection and Recognition Research\",\"className\":\"object-contain\"}],[\"$\",\"$L8\",null,{\"children\":\"T\"}]]}]}],[\"$\",\"div\",null,{\"className\":\"flex flex-1 flex-col justify-start gap-1\",\"children\":[[\"$\",\"time\",null,{\"className\":\"text-xs text-muted-foreground\",\"children\":\"Sep 2023 â€“ Mar 2025\"}],[\"$\",\"h2\",null,{\"className\":\"font-semibold leading-none\",\"children\":\"Target Detection and Recognition Research\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-muted-foreground\",\"children\":\"Xi'an, China\"}],[\"$\",\"span\",null,{\"className\":\"prose dark:prose-invert text-sm text-muted-foreground\",\"children\":\"Developed high-fidelity virtual environments for dataset generation; Improved robustness under varied conditions.\"}]]}],false]}]}],[\"$\",\"$L5\",\"Biological Computing Model Suite (Huawei)Jun 2022 â€“ Jan 2023\",{\"delay\":0.65,\"children\":[\"$\",\"li\",null,{\"className\":\"relative ml-10 py-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"absolute -left-16 top-2 flex items-center justify-center bg-white rounded-full\",\"children\":[\"$\",\"$L6\",null,{\"className\":\"border size-12 m-auto\",\"children\":[[\"$\",\"$L7\",null,{\"src\":\"/dna.jpg\",\"alt\":\"Biological Computing Model Suite (Huawei)\",\"className\":\"object-contain\"}],[\"$\",\"$L8\",null,{\"children\":\"B\"}]]}]}],[\"$\",\"div\",null,{\"className\":\"flex flex-1 flex-col justify-start gap-1\",\"children\":[[\"$\",\"time\",null,{\"className\":\"text-xs text-muted-foreground\",\"children\":\"Jun 2022 â€“ Jan 2023\"}],[\"$\",\"h2\",null,{\"className\":\"font-semibold leading-none\",\"children\":\"Biological Computing Model Suite (Huawei)\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-muted-foreground\",\"children\":\"Xi'an, China\"}],[\"$\",\"span\",null,{\"className\":\"prose dark:prose-invert text-sm text-muted-foreground\",\"children\":\"Developed models using MindSpore; Achievements integrated into Huawei's standard library.\"}]]}],false]}]}],[\"$\",\"$L5\",\"NSFC Key Program: Collaborative Learning and OptimizationSep 2023 â€“ Sep 2024\",{\"delay\":0.7,\"children\":[\"$\",\"li\",null,{\"className\":\"relative ml-10 py-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"absolute -left-16 top-2 flex items-center justify-center bg-white rounded-full\",\"children\":[\"$\",\"$L6\",null,{\"className\":\"border size-12 m-auto\",\"children\":[[\"$\",\"$L7\",null,{\"src\":\"/NSFC.png\",\"alt\":\"NSFC Key Program: Collaborative Learning and Optimization\",\"className\":\"object-contain\"}],[\"$\",\"$L8\",null,{\"children\":\"N\"}]]}]}],[\"$\",\"div\",null,{\"className\":\"flex flex-1 flex-col justify-start gap-1\",\"children\":[[\"$\",\"time\",null,{\"className\":\"text-xs text-muted-foreground\",\"children\":\"Sep 2023 â€“ Sep 2024\"}],[\"$\",\"h2\",null,{\"className\":\"font-semibold leading-none\",\"children\":\"NSFC Key Program: Collaborative Learning and Optimization\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-muted-foreground\",\"children\":\"Xi'an, China\"}],[\"$\",\"span\",null,{\"className\":\"prose dark:prose-invert text-sm text-muted-foreground\",\"children\":\"Integrated deep learning and evolutionary optimization for improving neural network performance and interpretability.\"}]]}],false]}]}]]}]}]]}]}],[\"$\",\"section\",null,{\"id\":\"contact\",\"children\":[\"$\",\"div\",null,{\"className\":\"grid items-center justify-center gap-4 px-4 text-center md:px-6 w-full py-12\",\"children\":[\"$\",\"$L5\",null,{\"delay\":0.64,\"children\":[\"$\",\"div\",null,{\"className\":\"space-y-3\",\"children\":[[\"$\",\"div\",null,{\"className\":\"inline-block rounded-lg bg-foreground text-background px-3 py-1 text-sm\",\"children\":\"Contact\"}],[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold tracking-tighter sm:text-5xl\",\"children\":\"Get in Touch\"}],[\"$\",\"p\",null,{\"className\":\"mx-auto max-w-[600px] text-muted-foreground md:text-xl/relaxed lg:text-base/relaxed xl:text-xl/relaxed\",\"children\":[\"If you have any questions, feel free to contact me at \",\" \",[\"$\",\"$La\",null,{\"href\":\"mailto:lyting71@gmail.com\",\"className\":\"text-blue-500 hover:underline\",\"children\":\"lyting71@gmail.com\"}],\" \",\"and I'll respond whenever I can.\"]}]]}]}]}]}]]}]],null],null]},[[\"$\",\"html\",null,{\"lang\":\"en\",\"suppressHydrationWarning\":true,\"children\":[\"$\",\"body\",null,{\"className\":\"min-h-screen bg-background font-sans antialiased max-w-2xl mx-auto py-12 sm:py-24 px-6 __variable_d65c78\",\"children\":[\"$\",\"$Lc\",null,{\"attribute\":\"class\",\"defaultTheme\":\"light\",\"children\":[\"$\",\"$Ld\",null,{\"delayDuration\":0,\"children\":[[\"$\",\"$Le\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$Lf\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[],\"styles\":null}],[\"$\",\"div\",null,{\"className\":\"pointer-events-none fixed inset-x-0 bottom-0 z-30 mx-auto mb-4 flex origin-bottom h-full max-h-14\",\"children\":[[\"$\",\"div\",null,{\"className\":\"fixed bottom-0 inset-x-0 h-16 w-full bg-background to-transparent backdrop-blur-lg [-webkit-mask-image:linear-gradient(to_top,black,transparent)] dark:bg-background\"}],[\"$\",\"$L10\",null,{\"className\":\"z-50 pointer-events-auto relative mx-auto flex min-h-full h-full items-center px-1 bg-background [box-shadow:0_0_0_1px_rgba(0,0,0,.03),0_2px_4px_rgba(0,0,0,.05),0_12px_24px_rgba(0,0,0,.05)] transform-gpu dark:[border:1px_solid_rgba(255,255,255,.1)] dark:[box-shadow:0_-20px_80px_-20px_#ffffff1f_inset] \",\"children\":[[[\"$\",\"$L11\",\"/\",{\"children\":[\"$\",\"$L12\",null,{\"children\":[[\"$\",\"$L13\",null,{\"asChild\":true,\"children\":[\"$\",\"$La\",null,{\"href\":\"/\",\"className\":\"inline-flex items-center justify-center whitespace-nowrap text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50 hover:bg-accent hover:text-accent-foreground rounded-full size-12\",\"children\":[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-home size-4\",\"children\":[[\"$\",\"path\",\"y5dka4\",{\"d\":\"m3 9 9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z\"}],[\"$\",\"polyline\",\"e2us08\",{\"points\":\"9 22 9 12 15 12 15 22\"}],\"$undefined\"]}]}]}],[\"$\",\"$L14\",null,{\"children\":[\"$\",\"p\",null,{\"children\":\"Home\"}]}]]}]}],[\"$\",\"$L11\",\"/blog\",{\"children\":[\"$\",\"$L12\",null,{\"children\":[[\"$\",\"$L13\",null,{\"asChild\":true,\"children\":[\"$\",\"$La\",null,{\"href\":\"/blog\",\"className\":\"inline-flex items-center justify-center whitespace-nowrap text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50 hover:bg-accent hover:text-accent-foreground rounded-full size-12\",\"children\":[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-notebook size-4\",\"children\":[[\"$\",\"path\",\"aawbzj\",{\"d\":\"M2 6h4\"}],[\"$\",\"path\",\"l0bgd4\",{\"d\":\"M2 10h4\"}],[\"$\",\"path\",\"1gsvsf\",{\"d\":\"M2 14h4\"}],[\"$\",\"path\",\"1bu2t1\",{\"d\":\"M2 18h4\"}],[\"$\",\"rect\",\"1nb95v\",{\"width\":\"16\",\"height\":\"20\",\"x\":\"4\",\"y\":\"2\",\"rx\":\"2\"}],[\"$\",\"path\",\"rotuqe\",{\"d\":\"M16 2v20\"}],\"$undefined\"]}]}]}],[\"$\",\"$L14\",null,{\"children\":[\"$\",\"p\",null,{\"children\":\"Blog\"}]}]]}]}]],[\"$\",\"$L15\",null,{\"orientation\":\"vertical\",\"className\":\"h-full\"}],[[\"$\",\"$L11\",\"GitHub\",{\"children\":[\"$\",\"$L12\",null,{\"children\":[[\"$\",\"$L13\",null,{\"asChild\":true,\"children\":[\"$\",\"$La\",null,{\"href\":\"https://github.com/lyt71\",\"className\":\"inline-flex items-center justify-center whitespace-nowrap text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50 hover:bg-accent hover:text-accent-foreground rounded-full size-12\",\"children\":[\"$\",\"svg\",null,{\"viewBox\":\"0 0 438.549 438.549\",\"className\":\"size-4\",\"children\":[\"$\",\"path\",null,{\"fill\":\"currentColor\",\"d\":\"$16\"}]}]}]}],[\"$\",\"$L14\",null,{\"children\":[\"$\",\"p\",null,{\"children\":\"GitHub\"}]}]]}]}],[\"$\",\"$L11\",\"email\",{\"children\":[\"$\",\"$L12\",null,{\"children\":[[\"$\",\"$L13\",null,{\"asChild\":true,\"children\":[\"$\",\"$La\",null,{\"href\":\"mailto:lyting71@gmail.com\",\"className\":\"inline-flex items-center justify-center whitespace-nowrap text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50 hover:bg-accent hover:text-accent-foreground rounded-full size-12\",\"children\":[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-mail size-4\",\"children\":[[\"$\",\"rect\",\"18n3k1\",{\"width\":\"20\",\"height\":\"16\",\"x\":\"2\",\"y\":\"4\",\"rx\":\"2\"}],[\"$\",\"path\",\"1ocrg3\",{\"d\":\"m22 7-8.97 5.7a1.94 1.94 0 0 1-2.06 0L2 7\"}],\"$undefined\"]}]}]}],[\"$\",\"$L14\",null,{\"children\":[\"$\",\"p\",null,{\"children\":\"email\"}]}]]}]}],[\"$\",\"$L11\",\"cv\",{\"children\":[\"$\",\"$L12\",null,{\"children\":[[\"$\",\"$L13\",null,{\"asChild\":true,\"children\":[\"$\",\"$La\",null,{\"href\":\"/Yiting_Liu_CV.pdf\",\"className\":\"inline-flex items-center justify-center whitespace-nowrap text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50 hover:bg-accent hover:text-accent-foreground rounded-full size-12\",\"children\":[\"$\",\"svg\",null,{\"viewBox\":\"0 0 24 24\",\"fill\":\"currentColor\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"className\":\"size-4\",\"children\":[[\"$\",\"title\",null,{\"children\":\"CV\"}],[\"$\",\"path\",null,{\"d\":\"M4 2a2 2 0 0 0-2 2v16c0 1.1.9 2 2 2h16a2 2 0 0 0 2-2V8l-6-6H4zm13 1.5L20.5 7H17a2 2 0 0 1-2-2V3.5z\"}]]}]}]}],[\"$\",\"$L14\",null,{\"children\":[\"$\",\"p\",null,{\"children\":\"cv\"}]}]]}]}]],[\"$\",\"$L15\",null,{\"orientation\":\"vertical\",\"className\":\"h-full py-2\"}],[\"$\",\"$L11\",null,{\"children\":[\"$\",\"$L12\",null,{\"children\":[[\"$\",\"$L13\",null,{\"asChild\":true,\"children\":[\"$\",\"$L17\",null,{}]}],[\"$\",\"$L14\",null,{\"children\":[\"$\",\"p\",null,{\"children\":\"Theme\"}]}]]}]}]]}]]}]]}]}]}]}],null],null],\"couldBeIntercepted\":false,\"initialHead\":[false,\"$L18\"],\"globalErrorComponent\":\"$19\",\"missingSlots\":\"$W1a\"}]]\n"])</script><script>self.__next_f.push([1,"18:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"Yiting Liu\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"Ph.D. Candidate, Control Science and Engineering, Xidian University, Xi'an, China\"}],[\"$\",\"meta\",\"4\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"5\",{\"name\":\"googlebot\",\"content\":\"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:title\",\"content\":\"Yiting Liu\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:description\",\"content\":\"Ph.D. Candidate, Control Science and Engineering, Xidian University, Xi'an, China\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:url\",\"content\":\"https://lyt71.github.io\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:site_name\",\"content\":\"Yiting Liu\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"12\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:title\",\"content\":\"Yiting Liu\"}],[\"$\",\"meta\",\"14\",{\"name\":\"twitter:description\",\"content\":\"Ph.D. Candidate, Control Science and Engineering, Xidian University, Xi'an, China\"}],[\"$\",\"link\",\"15\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]]\n3:null\n"])</script></body></html>